<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta content="width=device-width,initial-scale=1,minimum-scale=1" name="viewport"><meta content="ie=edge" http-equiv="X-UA-Compatible"><meta content="#fff" name="theme-color" id="theme-color"><meta content="My daily record and my safehouse" name="description"><link href="/" rel="icon"><title>实用统计学（四）</title><meta content="实用统计学（四）" property="og:title"><meta content="https://chengziyu.xyz/p/181ef7d8/index.html" property="og:url"><meta content="/assets/img/haibra4.jpg" property="og:img"><meta content="My daily record and my safehouse" property="og:img"><meta content="article" property="og:type"><meta content="2022-07-12" property="og:article:published_time"><meta content="2022-07-22" property="og:article:modified_time"><meta content="是橙子呀" property="og:article:author"><meta content="Statistic" property="og:article:tag"><meta content="R" property="og:article:tag"><link href="//at.alicdn.com/t/font_1946621_i1kgafibvw.css" rel="preload" as="style"><link href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css" rel="preload" as="style"><link href="/css/main.css" rel="preload" as="style"><link href="//instant.page/5.1.0" rel="modulepreload"><link href="/css/main.css" rel="stylesheet"><link href="//at.alicdn.com/t/font_1946621_i1kgafibvw.css" rel="stylesheet"><link href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css" rel="stylesheet"><link href="/js/lib/lightbox/baguetteBox.min.css" rel="stylesheet"><script>function loadScript(e,t){var n=document.createElement("script");n.src=e,t&&(n.onload=t),n.async=!0,document.body.appendChild(n)}function loadCSS(e,t,n){var a=document.createElement("link");a.ref="stylesheet",a.href=e,a.dataset[t]=n,document.head.appendChild(a)}function changeCSS(e,t,n){var t=document.querySelector(t),a=document.createElement("link");a.setAttribute("rel","stylesheet"),a.setAttribute("href",e),a.dataset.prism=n,document.head.replaceChild(a,t)}</script><script>function prismThemeChange(){"dark"===document.getElementById("theme-color").dataset.mode?document.querySelector("[data-prism]")?changeCSS("/js/lib/prism/prism-tomorrow.min.css","[data-prism]","prism-tomorrow"):loadCSS("/js/lib/prism/prism-tomorrow.min.css","prism","prism-tomorrow"):document.querySelector("[data-prism]")?changeCSS("/js/lib/prism/prism-solarizedlight.min.css","[data-prism]","prism-solarizedlight"):loadCSS("/js/lib/prism/prism-solarizedlight.min.css","prism","prism-solarizedlight")}prismThemeChange()</script><script>var reverseDarkList={dark:"light",light:"dark"},themeColor={dark:"#1c1c1e",light:"#fff"},getCssMediaQuery=function(){return window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"},reverseDarkModeSetting=function(){var e=localStorage.getItem("user-color-scheme");if(reverseDarkList[e])e=reverseDarkList[e];else{if(null!==e)return;e=reverseDarkList[getCssMediaQuery()]}return localStorage.setItem("user-color-scheme",e),e}</script><script>var setDarkmode=function(e){e=e||localStorage.getItem("user-color-scheme");e===getCssMediaQuery()?(document.documentElement.removeAttribute("data-user-color-scheme"),localStorage.removeItem("user-color-scheme"),document.getElementById("theme-color").content=themeColor[e],document.getElementById("theme-color").dataset.mode=e):reverseDarkList[e]?(document.documentElement.setAttribute("data-user-color-scheme",e),document.getElementById("theme-color").content=themeColor[e],document.getElementById("theme-color").dataset.mode=e):(document.documentElement.removeAttribute("data-user-color-scheme"),localStorage.removeItem("user-color-scheme"),document.getElementById("theme-color").content=themeColor[getCssMediaQuery()],document.getElementById("theme-color").dataset.mode=getCssMediaQuery()),prismThemeChange()};setDarkmode()</script><link href="/js/lib/lightbox/baguetteBox.min.js" rel="preload" as="script"><link href="/js/lib/lightbox/baguetteBox.min.css" rel="preload" as="style"><link href="/js/lib/lozad.min.js" rel="preload" as="script"><link href="//cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-svg.js" rel="prefetch" as="script"><meta content="Hexo 5.4.2" name="generator"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style></head><body><div class="wrapper"><nav class="navbar"><div class="navbar-logo"><a href="/" class="navbar-logo-main"><span class="navbar-logo-dsc">橙子安全屋</span></a></div><div class="navbar-menu"><a href="/" class="navbar-menu-item">首页 </a><a href="/archives" class="navbar-menu-item">归档 </a><a href="/tags" class="navbar-menu-item">标签 </a><a href="/categories" class="navbar-menu-item">分类 </a><a href="/about" class="navbar-menu-item">关于 </a><a href="/links" class="navbar-menu-item">友链 </a><button aria-label="Toggle dark mode" class="navbar-menu-item navbar-menu-btn darknavbar" id="dark"><i class="iconfont icon-weather"></i></button> <button aria-label="Toggle search" class="navbar-menu-item navbar-menu-btn searchnavbar" id="search"><!-- <i 
        class="iconfont icon-search" 
        style="font-size: 1.2rem; font-weight: 400;">
      </i> --> <svg aria-hidden="true" class="iconify iconify--ion" height="28" preserveAspectRatio="xMidYMid meet" role="img" viewBox="0 0 512 512" width="28" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 80a176 176 0 1 0 176 176A176 176 0 0 0 256 80Z" fill="none" stroke="currentColor" stroke-miterlimit="10" stroke-width="28"></path><path d="M232 160a72 72 0 1 0 72 72a72 72 0 0 0-72-72Z" fill="none" stroke="currentColor" stroke-miterlimit="10" stroke-width="28"></path><path d="M283.64 283.64L336 336" fill="none" stroke="currentColor" stroke-miterlimit="10" stroke-width="28" stroke-linecap="round"></path></svg></button></div></nav><div id="local-search" style="display:none"><input class="navbar-menu-item" id="search-input" placeholder="请输入搜索内容..."><div id="search-content"></div></div><div class="section-wrap"><div class="container"><div class="columns"><aside class="left-column"><div class="card card-author"><img alt="author avatar" class="author-img" height="88" src="/assets/img/haibra4.jpg" width="88"><p class="author-name">是橙子呀</p><p class="author-description">橙子碎碎念</p><div class="author-message"><a href="/archives" class="author-posts-count"><span>61</span> <span>文章</span> </a><a href="/categories" class="author-categories-count"><span>14</span> <span>分类</span> </a><a href="/tags" class="author-tags-count"><span>35</span> <span>标签</span></a></div></div><div class="sticky-tablet"><article class="display-when-two-columns spacer"><div class="card card-content toc-card"><div class="toc-header"><i class="iconfont icon-menu" style="padding-right:2px"></i>目录</div><ol class="toc"><li class="toc-item toc-level-2"><a href="#%E5%9B%9E%E5%BD%92-%E9%A2%84%E6%B5%8B" class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">回归 &amp; 预测</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a href="#%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92" class="toc-link"><span class="toc-number">1.0.1.</span> <span class="toc-text">多元线性回归</span></a></li><li class="toc-item toc-level-4"><a href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0" class="toc-link"><span class="toc-number">1.0.2.</span> <span class="toc-text">模型评估</span></a></li></ol></li><li class="toc-item toc-level-3"><a href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E9%80%90%E6%AD%A5%E5%9B%9E%E5%BD%92%E6%B3%95" class="toc-link"><span class="toc-number">1.1.</span> <span class="toc-text">模型选择和逐步回归法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9" class="toc-link"><span class="toc-number">1.1.0.1.</span> <span class="toc-text">模型选择</span></a></li></ol></li><li class="toc-item toc-level-4"><a href="#%E5%8A%A0%E6%9D%83%E5%9B%9E%E5%BD%92" class="toc-link"><span class="toc-number">1.1.1.</span> <span class="toc-text">加权回归</span></a></li></ol><li class="toc-item toc-level-3"><a href="#%E5%9B%9E%E5%BD%92%E4%B8%AD%E7%9A%84%E5%9B%A0%E5%AD%90%E5%8F%98%E9%87%8F" class="toc-link"><span class="toc-number">1.2.</span> <span class="toc-text">回归中的因子变量</span></a></li><li class="toc-item toc-level-3"><a href="#%E6%A3%80%E9%AA%8C%E5%81%87%E8%AE%BE%EF%BC%9A%E5%9B%9E%E5%BD%92%E8%AF%8A%E6%96%AD" class="toc-link"><span class="toc-number">1.3.</span> <span class="toc-text">检验假设：回归诊断</span></a></li><li class="toc-item toc-level-3"><a href="#%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92%E5%92%8C%E6%A0%B7%E6%9D%A1%E5%9B%9E%E5%BD%92" class="toc-link"><span class="toc-number">1.4.</span> <span class="toc-text">多项式回归和样条回归</span></a></li></div></article><article class="card card-content categories-widget"><div class="categories-card"><div class="categories-header"><i class="iconfont icon-fenlei" style="padding-right:2px"></i>分类</div><div class="categories-list"><a href="/categories/Daily-Record/"><div class="categories-list-item">Daily-Record <span class="categories-list-item-badge">25</span></div></a><a href="/categories/Code/"><div class="categories-list-item">Code <span class="categories-list-item-badge">31</span></div></a><a href="/categories/Daily-Record/Technology/"><div class="categories-list-item">Daily-Record/Technology <span class="categories-list-item-badge">20</span></div></a><a href="/categories/Code/BD/"><div class="categories-list-item">Code/BD <span class="categories-list-item-badge">16</span></div></a><a href="/categories/Code/DB/"><div class="categories-list-item">Code/DB <span class="categories-list-item-badge">4</span></div></a><a href="/categories/Code/DataScience/"><div class="categories-list-item">Code/DataScience <span class="categories-list-item-badge">4</span></div></a><a href="/categories/Code/Algorithm/"><div class="categories-list-item">Code/Algorithm <span class="categories-list-item-badge">3</span></div></a><a href="/categories/Code/shell/"><div class="categories-list-item">Code/shell <span class="categories-list-item-badge">4</span></div></a><a href="/categories/Daily-Record/Notes/"><div class="categories-list-item">Daily-Record/Notes <span class="categories-list-item-badge">3</span></div></a><a href="/categories/Daily-Record/novel/"><div class="categories-list-item">Daily-Record/novel <span class="categories-list-item-badge">2</span></div></a><a href="/categories/Markdown/"><div class="categories-list-item">Markdown <span class="categories-list-item-badge">1</span></div></a><a href="/categories/shell/"><div class="categories-list-item">shell <span class="categories-list-item-badge">1</span></div></a><a href="/categories/Statistic/"><div class="categories-list-item">Statistic <span class="categories-list-item-badge">5</span></div></a><a href="/categories/Statistic/Theory/"><div class="categories-list-item">Statistic/Theory <span class="categories-list-item-badge">5</span></div></a></div></div></article><article class="card card-content tags-widget"><div class="tags-card"><div class="tags-header"><i class="iconfont icon-biaoqian" style="padding-right:2px"></i>热门标签</div><div class="tags-list"><a href="/tags/Hexo/" title="Hexo"><div class="tags-list-item">Hexo</div></a><a href="/tags/Hive/" title="Hive"><div class="tags-list-item">Hive</div></a><a href="/tags/BD/" title="BD"><div class="tags-list-item">BD</div></a><a href="/tags/DataX/" title="DataX"><div class="tags-list-item">DataX</div></a><a href="/tags/Linux/" title="Linux"><div class="tags-list-item">Linux</div></a><a href="/tags/ETL/" title="ETL"><div class="tags-list-item">ETL</div></a><a href="/tags/Statistic/" title="Statistic"><div class="tags-list-item">Statistic</div></a><a href="/tags/Algorithm/" title="Algorithm"><div class="tags-list-item">Algorithm</div></a><a href="/tags/Spark/" title="Spark"><div class="tags-list-item">Spark</div></a><a href="/tags/Python/" title="Python"><div class="tags-list-item">Python</div></a><a href="/tags/Sqoop/" title="Sqoop"><div class="tags-list-item">Sqoop</div></a><a href="/tags/CDP/" title="CDP"><div class="tags-list-item">CDP</div></a><a href="/tags/Doris/" title="Doris"><div class="tags-list-item">Doris</div></a><a href="/tags/kafka/" title="kafka"><div class="tags-list-item">kafka</div></a><a href="/tags/SQL/" title="SQL"><div class="tags-list-item">SQL</div></a><a href="/tags/Redis/" title="Redis"><div class="tags-list-item">Redis</div></a></div></div></article></div></aside><main class="main-column"><article class="card card-content"><header><h1 class="post-title">实用统计学（四）</h1></header><div class="post-meta post-show-meta"><time datetime="2022-07-12T09:30:20.000Z"><i class="iconfont icon-calendar" style="margin-right:2px"></i> <span>2022-07-12</span> </time><span class="dot"></span> <a href="/categories/Statistic/" class="post-meta-link">Statistic </a><a href="/categories/Statistic/Theory/" class="post-meta-link">Theory </a><span class="dot"></span> <span>2.3k 字</span></div><div class="post-meta post-show-meta" style="margin-top:-10px"><div style="display:flex;align-items:center"><i class="iconfont icon-biaoqian" style="margin-right:2px;font-size:1.15rem"></i> <a href="/tags/Statistic/" class="post-meta-link">Statistic </a><span class="dot"></span> <a href="/tags/R/" class="post-meta-link">R</a></div></div><div class="post-content" id="section"><span id="more"></span><h2 id="回归-预测"><a href="#回归-预测" class="header-anchor"></a>回归 &amp; 预测</h2><p>回归可用于预测和解释</p><p><strong>回归主要用于传统的解释性建模而不是预测。</strong></p><table><thead><tr><th>概念</th><th>定义</th></tr></thead><tbody><tr><td>响应变量（特征向量）</td><td>想要预测的变量。同义词：因变量、变量 Y、目标、结果</td></tr><tr><td>自变量（预测变量）</td><td>用于预测响应的变量。同义词：自变量、变量 X、特征、属性</td></tr><tr><td>记录</td><td>一个表示特定个体或实例的向量，由因子和结果值组成。同义词：行、案例、实例、示例</td></tr><tr><td>截距</td><td>回归线的截距，即当 X = 0 时的预测值。</td></tr><tr><td>回归系数</td><td>回归线的斜率。同义词：斜率、参数估计值、权重</td></tr><tr><td>拟合值</td><td>从回归线获得的估计值 。同义词：预测值</td></tr><tr><td>残差</td><td>观测值和拟合值之间的差异。同义词：误差</td></tr><tr><td>残差平方和</td><td>残差值的平方和（RSS）</td></tr><tr><td>最小二乘法</td><td>一种通过最小化残差的平方和而拟合回归的方法。同义词：普通最小二乘法（OLS）回归</td></tr><tr><td>R使用lm函数拟合线性回归</td><td></td></tr></tbody></table><h4 id="多元线性回归"><a href="#多元线性回归" class="header-anchor"></a>多元线性回归</h4><table><thead><tr><th>概念</th><th>定义</th></tr></thead><tbody><tr><td>均方根误差</td><td>回归均方误差的平方根，是比较回归模型时使用最广泛的度量。同义词：RMSE</td></tr><tr><td>标准残差</td><td>与均方根误差的计算一样，只是根据自由度做了调整。同义词：RSE</td></tr><tr><td>R 方</td><td>可以被模型解释的变异的比例，值介于 0 到 1 之间。同义词：决定系数、$R^2$</td></tr><tr><td>t 统计量</td><td>预测因子的系数，除以系数的标准误差。它提供了一种比较模型中变量重要性的度量。</td></tr><tr><td>加权回归</td><td>在回归中，记录具有不同的权重。</td></tr></tbody></table><pre class="language-R" data-language="R"><code class="language-R">house_lm &lt;- lm(AdjSalePrice ~ SqFtTotLiving + SqFtLot + Bathrooms +
              Bedrooms + BldgGrade,
              data=house, na.action=na.omit)</code></pre><h4 id="模型评估"><a href="#模型评估" class="header-anchor"></a>模型评估</h4><p>均方根误差（RMSE）<br>$RSE=\sqrt{\frac{\sum_{i=1}<sup>n(y_i-\hat{y_i})</sup>2}{(n)}}$<br>标准残差（RSE）<br>$RSE=\sqrt{\frac{\sum_{i=1}<sup>n(y_i-\hat{y_i})</sup>2}{(n-p-1)}}$<br>对于线性回归而言，均方根误差和标准残差之间的差异在实践中会非常小，尤其是在大数据应用中。<br>R 方统计量、t 统计量<br>$t_b=\frac{\hat{b}}{SE(\hat{b})}$</p><p>交叉验证——经典的统计回归度量（R方、F 统计量和 p值）都是“样本内”（in-sample）度量。k 折（fold）交叉验证的算法如下。<br>(1) 取出 1/k 的数据，作为验证样本。<br>(2) 用余下的数据训练模型。<br>(3) 将训练模型应用于验证集上（进行打分），并记录所需的模型评估指标。<br>(4) 将最初取出的 1/k 数据放回，再取出 1/k 数据，其中不包括上一次取出的任何记录。<br>(5) 重复第 2 步和第 3 步。<br>(6) 重复上述步骤，直至验证集使用了每个记录。<br>(7) 对模型评估度量取平均或进行组合。<br>上面将数据划分为训练样本和验证样本的过程，也被称为折。</p><h3 id="模型选择和逐步回归法"><a href="#模型选择和逐步回归法" class="header-anchor"></a>模型选择和逐步回归法</h3><p>奥卡姆剃刀原则（principle of Occam’s razor）：在其他条件相同的情况下，应优先选用更简单的模型而不是更复杂的模型<br>添加额外的变量，几乎总会降低均方根误差并增大 R方</p><p>回归的 AIC 的计算：$AIC= 2P+nlog(RSS/n)$<br>P 是变量的数量，n 是记录的数量。目标是找出使 AIC 最小的模型。如果模型具有 k个额外变量，那么惩罚项为 2k。<br>AIC变体。</p><ul><li>AICc：针对小规模样本修正的 AIC。</li><li>BIC（贝叶斯信息准则）：类似于 AIC，但是在模型中额外添加了变量，因此具有更强的惩罚。</li><li>Mallows Cp：AIC 的一种变体，由 Colin Mallows 提出。</li></ul><h5 id="模型选择"><a href="#模型选择" class="header-anchor"></a>模型选择</h5><ul><li>全子集回归法（all subset regression）【代价太高】</li><li>stepAIC(使用了逐步回归法，通过连续地添加并丢弃预<br>测因子，发现可降低 AIC 的模型)【r的mass包】</li></ul><p>惩罚回归的思想类似于 AIC。拟合模型的函数并不是显式地搜索一组离散的模型，而是添加了一个新限制，对有多个变量（参数）的模型进行惩罚。惩罚回归不像逐步回归、前向和后向选择那样要完全清除预测变量，而是通过减少系数来应用惩罚，在一些情况下，甚至会减少至接近于 0。常见的惩罚回归是岭回归和 LASSO 回归</p><p>全子集回归和逐步回归是“样本内”方法。这意味着模型选取可能会受限于过拟合，不能很好地应用于新数据。为了避免出现这一问题，一种常用的方法是使用交叉验证去验证模型。在线性回归中，过拟合通常不是大问题，因为线性回归对数据给出的是一种简单（线性）全局结构。对于更为复杂的模型而言，尤其是响应本地数据结构的迭代过程，交叉验证是一种非常重要的工具</p><h4 id="加权回归"><a href="#加权回归" class="header-anchor"></a>加权回归</h4><ul><li>适用情况<ul><li>反方差权重（当不同观测值使用了不同的精度测量时）</li><li>分析聚合的数据，加权变量编码了聚合数据中每行代表了多少个原始观测值<br>加权回归用于拟合函数中，可以对特定记录给予更大或更小的权重。</li></ul></li></ul><h3 id="回归中的因子变量"><a href="#回归中的因子变量" class="header-anchor"></a>回归中的因子变量</h3><p>因子变量（factor variable）也称为分类变量，它是一组数量有限的离散<br>虚拟变量<br>　　二元的 0/1 变量，通过对因子数据重新编码得到，可用于回归模型或其他模型。<br>参考编码<br>　　统计学家最常使用的编码类型。它以因子的一层作为参考层，并将其他因子与参考<br>层进行对比。<br>　　同义词：编码处理<br>独热编码（one hot encoder）<br>　　机器学习领域中常用的一种编码。它保留了所有的因子层。虽然该编码适用于部分<br>机器学习算法，但并不适用于多元线性回归。<br>偏差编码<br>　　在编码中用于对比的并不是参考层，而是将每一层与整体均值进行对比。<br>　　同义词：总和对照（sum contrasts）编码</p><p>近邻算法和树模型中，独热编码是因子变量的标准表示方式</p><p>有序因子变量(因子变量体现出了因子的层级)</p><p>解释回归方程<br>相关变量<br>　　当预测变量高度相关时，难以解释单个回归系数。<br>多重共线性<br>　　当预测变量间存在完美的或近乎完美的相关性时，回归是不稳定的，或者说是不可能计算的。<br>　　同义词：共线性<br>混淆变量<br>　　一种重要的预测变量。忽视该变量可导致回归方程给出伪关系。<br>主效应<br>　　预测变量和结果变量之间的关系，该关系独立于其他的变量。<br>交互作用<br>　　两个或两个以上预测变量和响应之间的相互依赖关系。</p><p>对于树模型、聚类和最近邻等非回归方法，多重共线性可能并不会构成问题。在这些非回归方法中，可能会建议保留 P 个虚拟变量，而非 P-1 个。这就是说，即便是在这些方法中，非冗余的预测变量可能依然是个优点。</p><h3 id="检验假设：回归诊断"><a href="#检验假设：回归诊断" class="header-anchor"></a>检验假设：回归诊断</h3><p>鉴于离群值可能会在小规模数据集中导致问题，关注离群值主要是为了发现数据中存在的问题，或是确定异常所在。</p><ul><li>单个记录（包括回归离群值）可以对小规模数据集的回归方程产生很大的影响。但是在大数据中，这种效果却荡然无存。</li><li>如果将回归模型用于形式推断（如 p 值等），那么应该检验对残差分布的一些假设。但是对于数据科学而言，残差分布通常无关紧要。</li><li>偏残差图可以用于定性地评估每个回归项的拟合情况，这可能会得出另一种模型声明</li></ul><h3 id="多项式回归和样条回归"><a href="#多项式回归和样条回归" class="header-anchor"></a>多项式回归和样条回归</h3><p>多项式回归<br>　　在回归方程中添加了多项式项，例如平方项、三次方项等。<br>　　多项式回归只捕获了非线性关系的部分曲率。添加高阶项（例如三次方项），通常会导致回归线中出现不期望的“摇摆”（wiggliness）现象。</p><p>样条回归<br>　　使用一系列多项式片段去拟合一条平滑曲线。<br>结点<br>　　分隔样条片段的值。<br>广义加性模型<br>　　可以自动选择结点的样条模型。<br>　　同义词：GAM</p><p>从本质上讲，所有响应不能表示为预测变量（或预测变量的某<br>种转换）的线性组合的模型，都是非线性的。非线性回归模型需要做数值优化，因此更难以拟合，计算的强度也更大。如有可能应尽量使用线性模型</p></div><div><div class="copyright note-warning post-note" style="margin-top:42px"><p><span style="font-weight:700">作者：</span><a href="/about" rel="nofollow noopener noreferrer" target="_blank"> 是橙子呀</a></p><p><span style="font-weight:700">文章链接：</span><a href="https://chengziyu.xyz/p/181ef7d8/" rel="nofollow noopener noreferrer" target="_blank"> https://chengziyu.xyz/p/181ef7d8/</a></p><p><span style="font-weight:700">版权声明：</span>本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank">CC BY-NC-SA 4.0 协议</a>。转载请注明出处！</p></div></div></article><div class="nav"><div class="nav-item-prev"><a href="/p/bff17e60/" class="nav-link"><i class="iconfont icon-left nav-prev-icon"></i><div><div class="nav-label">上一篇</div><div class="nav-title">Git_Record</div></div></a></div><div class="nav-item-next"><a href="/p/80f66610/" class="nav-link"><div><div class="nav-label">下一篇</div><div class="nav-title">数据清洗(3)</div></div><i class="iconfont icon-right nav-next-icon"></i></a></div></div><div class="card card-content toc-card" id="mobiletoc"><div class="toc-header"><i class="iconfont icon-menu" style="padding-right:2px"></i>目录</div><ol class="toc"><li class="toc-item toc-level-2"><a href="#%E5%9B%9E%E5%BD%92-%E9%A2%84%E6%B5%8B" class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">回归 &amp; 预测</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a href="#%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92" class="toc-link"><span class="toc-number">1.0.1.</span> <span class="toc-text">多元线性回归</span></a></li><li class="toc-item toc-level-4"><a href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0" class="toc-link"><span class="toc-number">1.0.2.</span> <span class="toc-text">模型评估</span></a></li></ol></li><li class="toc-item toc-level-3"><a href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E9%80%90%E6%AD%A5%E5%9B%9E%E5%BD%92%E6%B3%95" class="toc-link"><span class="toc-number">1.1.</span> <span class="toc-text">模型选择和逐步回归法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9" class="toc-link"><span class="toc-number">1.1.0.1.</span> <span class="toc-text">模型选择</span></a></li></ol></li><li class="toc-item toc-level-4"><a href="#%E5%8A%A0%E6%9D%83%E5%9B%9E%E5%BD%92" class="toc-link"><span class="toc-number">1.1.1.</span> <span class="toc-text">加权回归</span></a></li></ol><li class="toc-item toc-level-3"><a href="#%E5%9B%9E%E5%BD%92%E4%B8%AD%E7%9A%84%E5%9B%A0%E5%AD%90%E5%8F%98%E9%87%8F" class="toc-link"><span class="toc-number">1.2.</span> <span class="toc-text">回归中的因子变量</span></a></li><li class="toc-item toc-level-3"><a href="#%E6%A3%80%E9%AA%8C%E5%81%87%E8%AE%BE%EF%BC%9A%E5%9B%9E%E5%BD%92%E8%AF%8A%E6%96%AD" class="toc-link"><span class="toc-number">1.3.</span> <span class="toc-text">检验假设：回归诊断</span></a></li><li class="toc-item toc-level-3"><a href="#%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92%E5%92%8C%E6%A0%B7%E6%9D%A1%E5%9B%9E%E5%BD%92" class="toc-link"><span class="toc-number">1.4.</span> <span class="toc-text">多项式回归和样条回归</span></a></li></div></main><aside class="right-column"><div class="sticky-widescreen"><article class="card card-content toc-card"><div class="toc-header"><i class="iconfont icon-menu" style="padding-right:2px"></i>目录</div><ol class="toc"><li class="toc-item toc-level-2"><a href="#%E5%9B%9E%E5%BD%92-%E9%A2%84%E6%B5%8B" class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">回归 &amp; 预测</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a href="#%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92" class="toc-link"><span class="toc-number">1.0.1.</span> <span class="toc-text">多元线性回归</span></a></li><li class="toc-item toc-level-4"><a href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0" class="toc-link"><span class="toc-number">1.0.2.</span> <span class="toc-text">模型评估</span></a></li></ol></li><li class="toc-item toc-level-3"><a href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E5%92%8C%E9%80%90%E6%AD%A5%E5%9B%9E%E5%BD%92%E6%B3%95" class="toc-link"><span class="toc-number">1.1.</span> <span class="toc-text">模型选择和逐步回归法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9" class="toc-link"><span class="toc-number">1.1.0.1.</span> <span class="toc-text">模型选择</span></a></li></ol></li><li class="toc-item toc-level-4"><a href="#%E5%8A%A0%E6%9D%83%E5%9B%9E%E5%BD%92" class="toc-link"><span class="toc-number">1.1.1.</span> <span class="toc-text">加权回归</span></a></li></ol><li class="toc-item toc-level-3"><a href="#%E5%9B%9E%E5%BD%92%E4%B8%AD%E7%9A%84%E5%9B%A0%E5%AD%90%E5%8F%98%E9%87%8F" class="toc-link"><span class="toc-number">1.2.</span> <span class="toc-text">回归中的因子变量</span></a></li><li class="toc-item toc-level-3"><a href="#%E6%A3%80%E9%AA%8C%E5%81%87%E8%AE%BE%EF%BC%9A%E5%9B%9E%E5%BD%92%E8%AF%8A%E6%96%AD" class="toc-link"><span class="toc-number">1.3.</span> <span class="toc-text">检验假设：回归诊断</span></a></li><li class="toc-item toc-level-3"><a href="#%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92%E5%92%8C%E6%A0%B7%E6%9D%A1%E5%9B%9E%E5%BD%92" class="toc-link"><span class="toc-number">1.4.</span> <span class="toc-text">多项式回归和样条回归</span></a></li></article><article class="card card-content"><div class="recent-posts-card"><div class="recent-posts-header"><i class="iconfont icon-wenzhang_huaban" style="padding-right:2px"></i>最近文章</div><div class="recent-posts-list"><div class="recent-posts-item"><div class="recent-posts-item-title">2022-09-24</div><a href="/p/7ffce599/"><div class="recent-posts-item-content">java记录</div></a></div><div class="recent-posts-item"><div class="recent-posts-item-title">2022-09-06</div><a href="/p/e81d6acd/"><div class="recent-posts-item-content">TableauOfAzurelane</div></a></div><div class="recent-posts-item"><div class="recent-posts-item-title">2022-09-02</div><a href="/p/77d31549/"><div class="recent-posts-item-content">vpf记录</div></a></div><div class="recent-posts-item"><div class="recent-posts-item-title">2022-08-31</div><a href="/p/9cf74209/"><div class="recent-posts-item-content">gcc安装</div></a></div></div></div></article></div></aside></div></div></div></div><footer class="footer"><div class="footer-container"><div><div class="footer-dsc"><span>Copyright © 2022 </span>&nbsp; <a href="/" class="footer-link">橙子安全屋</a></div></div><div class="BbeiAn-info"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">粤ICP备2022028508号-1</a></div><div class="BbeiAn-info"><span style="padding-left:25px;background:url(/img/beian.png) no-repeat left center"></span> <a href="https://beian.miit.gov.cn" rel="noopener" target="_blank">粤ICP备2022028508号-1</a><br></div><div class="footer-dsc">本站总访问量<span id="busuanzi_value_site_pv"></span>次 <span>&nbsp;|&nbsp;</span> 本站总访客数<span id="busuanzi_value_site_uv"></span>次</div></div></footer><a class="basebutton" aria-label="回到顶部" id="scrollbutton" role="button"><i class="iconfont button-icon icon-arrowleft"></i> </a><a class="basebutton" aria-label="menu button" id="menubutton" role="button"><i class="iconfont button-icon icon-menu"></i> </a><a class="basebutton" aria-label="控制中心" id="popbutton" role="button"><i class="iconfont button-icon icon-expand"></i> </a><a class="basebutton darkwidget" aria-label="夜色模式" id="darkbutton" role="button"><i class="iconfont button-icon icon-weather"></i> </a><a class="basebutton searchwidget" aria-label="搜索" id="searchbutton" role="button"><i class="iconfont button-icon icon-search"></i></a><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><script src="//cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-svg.js"></script><script>var addImgLayout=function(){for(var t=document.querySelectorAll(".post-content img"),e=0;e<t.length;e++){var a=document.createElement("a"),l=(a.setAttribute("href",t[e].getAttribute("data-src")),a.setAttribute("aria-label","illustration"),a.style.cssText="width: 100%; display: flex; justify-content: center;",t[e].alt&&(a.dataset.caption=t[e].alt),a.dataset.nolink=!0,t[e].before(a),a.append(t[e]),document.createElement("div"));l.classList.add("gallery"),a.before(l),l.append(a)}baguetteBox.run(".gallery")}</script><script>loadScript("/js/lib/lightbox/baguetteBox.min.js",addImgLayout)</script><script src="/js/main.js"></script><script>loadScript("/js/lib/busuanzi.min.js")</script><script>var addLazyload=function(){lozad(".lozad",{load:function(a){a.srcset=a.getAttribute("data-src")},loaded:function(a){a.classList.add("loaded")}}).observe()}</script><script>loadScript("/js/lib/lozad.min.js",addLazyload)</script><script src="//instant.page/5.1.0" integrity="sha384-by67kQnR+pyfy8yWP4kPO12fHKRLHZPfEsiSXR8u2IKcTdxD805MGUXBzVPnkLHw" type="module"></script><script>setTimeout(()=>{localSearch("search.json")},0)</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({model:{jsonPath:"/live2dw/assets/assets/remu.model.json"},display:{superSample:3,width:200,height:400,position:"right",hOffset:60,vOffset:-30},mobile:{show:!0,scale:.5},react:{opacity:.8},log:!1,pluginJsPath:"lib/",pluginModelPath:"assets/",pluginRootPath:"live2dw/",tagMode:!1})</script></body></html>